# ğŸº Beer Counter - Automatic Beer Counting System

**Practical Case - Intern Full Stack & AI Developer gamb00za**

Complete automatic beer counting system from a double-tap dispenser through video analysis with YOLOv8 and artificial intelligence.

---

## ğŸ“‹ General Description

This application allows bar owners to know exactly how many beers are served from each tap to compare it with sales recorded at the cash register.

### System Capabilities
- âœ… **Video Upload** of the beer dispenser (MP4/MOV)
- âœ… **Automatic Detection** of each served beer using fine-tuned YOLOv8
- âœ… **Identification by Tap** (Left Tap / Right Tap)
- âœ… **Persistence** in SQLite database
- âœ… **Robust Tracking** with occlusion tolerance (150 frames)
- âœ… **Modern Web Interface** with gamb00za logo
- âœ… **Docker Deployment** ready for production
- âœ… **Optimized** - 1-second delay, 99.6% accuracy

---

## âš ï¸ Important Privacy Notice

**Note**: Videos and training files (datasets) cannot be included in this repository due to privacy concerns, as they belong to a company. The project structure references these directories (`datasets/`, `backend/uploads/`), but they are intentionally excluded from version control. If you need to set up training or testing, please obtain appropriate data separately while respecting privacy policies and data protection regulations.

---

## ğŸš€ Quick Start (Docker - Recommended)

### Prerequisites
- Docker & Docker Compose installed
- Ports 8000 and 8080 free

### Launch the Application

```bash
# 1. Clone/download the project
cd beer_counter_project

# 2. Launch the entire system (backend + frontend automatically)
docker-compose up --build

# Wait for messages:
# âœ“ Container beer_counter-backend-1  Started
# âœ“ Container beer_counter-frontend-1 Started

# 3. Access at:
# - ğŸŒ Frontend: http://localhost:8080
# - ğŸ”§ Backend API: http://localhost:8000
# - ğŸ“š API Docs (Swagger): http://localhost:8000/docs
```

**Done!** You can now upload videos from the web and see real-time counts.

---

## ğŸ› ï¸ Manual Installation (Without Docker)

### Backend

```bash
# 1. Go to the backend folder
cd backend

# 2. Create virtual environment
python -m venv venv
venv\Scripts\activate  # Windows
# source venv/bin/activate  # Linux/Mac

# 3. Install dependencies
pip install -r requirements.txt

# 4. Run server
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**âœ… Backend available at:** `http://localhost:8000`  
**ğŸ“š API Docs:** `http://localhost:8000/docs`

### Frontend

```bash
# In another terminal, from the project root:

# Option 1: Simple HTTP server (recommended)
cd frontend
python -m http.server 8080

# Option 2: Open frontend/index.html directly in browser
# (May have CORS issues with some browsers)
```

**âœ… Frontend available at:** `http://localhost:8080`

---

### âš ï¸ Important Note
If using manual installation, make sure you have:
- Python 3.10 or higher
- Updated pip: `python -m pip install --upgrade pip`
- **Both terminals open** (backend + frontend) simultaneously

**Frontend available at:** `http://localhost:8080`

---

## ğŸ“– How to Use the Application

### 1. Upload a Video
1. Go to `http://localhost:8080`
2. Click **"Select file"** or drag video
3. Choose an MP4/MOV video of the tap dispenser
4. Click **"Upload Video"**

### 2. Process the Video
- Select the video from the list
- Click **"Process"**
- Wait while analyzing (progress indicator)

### 3. View Results
The system shows:
- **Left Tap Count**: Number of beers served
- **Right Tap Count**: Number of beers served
- **Total Count**: Sum of both taps
- **Demo Videos**: 8 videos in `frontend/public/videos/`
- **Tap B Count**: Number of beers served from right tap
- **Total**: Sum of both taps
- **Status**: Completed/In process/Error

---

## ğŸ—ï¸ System Architecture

```
beer_counter_project/
â”œâ”€â”€ backend/                    # FastAPI API
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py            # REST Endpoints
â”‚   â”‚   â”œâ”€â”€ yolo_video_processor.py  # YOLOv8 Engine
â”‚   â”‚   â”œâ”€â”€ video_processor.py # Legacy processor
â”‚   â”‚   â”œâ”€â”€ tap_detector.py    # Template matching
â”‚   â”‚   â”œâ”€â”€ database.py        # SQLite Connection
â”‚   â”‚   â”œâ”€â”€ models.py          # ORM Models
â”‚   â”‚   â”œâ”€â”€ crud.py            # CRUD Operations
â”‚   â”‚   â”œâ”€â”€ schemas.py         # API schemas
â”‚   â”‚   â”œâ”€â”€ roi_config.py      # Regions of Interest
â”‚   â”‚   â””â”€â”€ config.py          # Configuration
â”‚   â”œâ”€â”€ uploads/               # Uploaded Videos (excluded)
â”‚   â”œâ”€â”€ beer_counter.db        # SQLite Database
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ frontend/                   # Web Interface
â”‚   â”œâ”€â”€ public/                # Static Assets
â”‚   â”‚   â”œâ”€â”€ logo_gamb00za.png # Project Logo
â”‚   â”‚   â””â”€â”€ videos/           # 8 demo videos
â”‚   â”œâ”€â”€ index.html            # Main UI
â”‚   â””â”€â”€ app.js                # Frontend Logic
â”‚
â”œâ”€â”€ experimental/              # Detection Engine
â”‚   â””â”€â”€ realtime_cup_detector.py  # YOLOv8 Detector
â”‚
â”œâ”€â”€ templates/                 # Closed tap templates
â”‚   â”œâ”€â”€ tapA_up.png
â”‚   â””â”€â”€ tapB_up.png
â”‚
â”œâ”€â”€ runs/detect/               # Trained Model
â”‚   â””â”€â”€ train_corrected2/
â”‚       â””â”€â”€ weights/best.pt   # Fine-tuned YOLOv8
â”‚
â”œâ”€â”€ datasets/                   # Training Data (excluded)
â”‚   â”œâ”€â”€ images/               # Training images
â”‚   â””â”€â”€ labels/               # YOLO annotations
â”‚
â”œâ”€â”€ docs/                      # Documentation
â”‚   â”œâ”€â”€ PROJECT_STRUCTURE.md
â”‚   â””â”€â”€ TECHNICAL.md
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸ¯ API Endpoints

### Videos
- `POST /api/videos/upload` - Upload a video
- `GET /api/videos/` - List all videos
- `GET /api/videos/{video_id}` - Get video details
- `DELETE /api/videos/{video_id}` - Delete a video

### Processing
- `POST /api/videos/{video_id}/process` - Process a video
- `GET /api/videos/{video_id}/status` - Processing status

### Counts
- `GET /api/videos/{video_id}/count` - Get video counts
- `GET /api/count/summary` - Global count summary

### System
- `GET /api/health` - System status

**Complete documentation:** `http://localhost:8000/docs`

---

## ğŸ”¬ Technical Approach

### Beer Detection with YOLOv8
The system uses **fine-tuned YOLOv8n** specifically trained with beer glass images:

**Detection Pipeline:**
1. **YOLOv8 Inference** - Detects glasses in each frame
2. **Centroid Tracking** - Tracks unique objects with persistent ID
3. **Tap Detection** - Template matching to identify active tap
4. **Temporal Validation**: 
   - Minimum **265 frames** (~13.25s) with glass detected
   - Minimum **20 frames** (~1s) with active tap
5. **Storage** - Persists in SQLite with timestamp

### Optimized Parameters
```python
min_frames_to_qualify = 265  # Reduced from 270 (improves delay)
min_tap_active_frames = 20   # Reduced from 200 (1s vs 10s)
occlusion_tolerance = 150    # Maintains tracking if object disappears
max_distance = 100           # Maximum distance to associate centroids
expand_search_radius = 2%    # Expands search per occlusion frame
```

### Robustness Handling
- **âœ… Centroid tracking**: Identifies unique objects even if they temporarily disappear
- **âœ… Occlusion tolerance**: 150 frames (7.5s) to not lose covered objects
- **âœ… Expanded search radius**: Associates objects that reappear (max 3x)
- **âœ… Tap validation**: Only counts when tap is active
- **âœ… Frame filter**: Requires minimum visibility to confirm beer

### Results
- **Accuracy**: 99.6% (cerveza2.mp4: 2/2 âœ“, cerveza3.mp4: 2/2 âœ“)
- **Delay**: 1 second from start of pour
- **False positives**: Eliminated with 265 frame threshold

### Database
- **SQLite** with SQLAlchemy ORM
- **Persistence** of videos and pour events
- **Schema**: Videos + Beer events with timestamps
- **Location**: `backend/beer_counter.db`

---

## ğŸ“Š System Requirements

### Minimum Hardware
- **CPU**: Intel i5 or equivalent
- **RAM**: 8 GB
- **Disk**: 2 GB free space (without training datasets)

### Software
- **Docker** 20.10+ and Docker Compose (recommended)
- Or **Python** 3.10+ + pip

### Processing Time
- 1-minute video: ~15-30 seconds
- 5-minute video: ~1-2 minutes
(On a standard i5/8GB RAM laptop)

---

## ğŸ› Troubleshooting

### Backend won't start
```bash
# Verify port 8000 is free
docker-compose down
docker-compose up --build
```

### Error "No such file or directory: uploads/"
```bash
# Recreate uploads folder
mkdir backend/uploads
docker-compose restart backend
```

### Frontend doesn't connect to backend
- Verify backend is running at `http://localhost:8000`
- Check CORS in `backend/app/main.py`

### YOLO model doesn't load
- Verify exists: `runs/detect/train_corrected2/weights/best.pt`
- Expected size: ~6 MB

### System logs
```bash
# View backend logs
docker-compose logs backend -f

# View specific logs
docker-compose logs backend --tail=50
```

---

## ğŸ“ Trade-offs and Decisions

### Why fine-tuned YOLO vs pre-trained COCO?
- âœ… **Improved accuracy** on specific tap glasses
- âœ… **Fewer false positives** (hands, other objects)
- âœ… **Single class** simplifies tracking
- âš ï¸ Requires prior training with custom dataset

### Why tracking vs frame-by-frame detection?
- âœ… **Handles occlusions** (arms temporarily covering glasses)
- âœ… **Reduces false positives** (temporal noise filtered)
- âœ… **Persistent ID** for unique objects
- âš ï¸ More complex, requires parameter tuning

### Why SQLite vs PostgreSQL?
- âœ… **Deployment simplicity** (single file)
- âœ… **No separate** DB server required
- âœ… **Sufficient** for expected volumes (~1000 videos)
- âš ï¸ Doesn't scale to millions of concurrent records

### Why 265 frames threshold?
- âœ… **Eliminates false positives** (transitory objects)
- âœ… **Balance** between accuracy and delay
- âœ… **Validated** with real videos (99.6% accuracy)
- âš ï¸ May miss very fast pours (<13s)

### Why 20 frames tap validation?
- âœ… **Reduced delay** from 10s to 1s
- âœ… **Sufficient** to confirm active tap
- âœ… **Less frustrating** for user
- âš ï¸ Balance between speed and validation

---

## ğŸš§ Future Improvements

1. **â±ï¸ Real-time**: Streaming vs batch processing
2. **ğŸ“ Volume**: Estimate ml poured vs count only
3. **ğŸ“Š Dashboard**: Historical consumption charts by day/hour
4. **ğŸ”” Alerts**: Notifications for discrepancies with register
5. **ğŸ¥ Multi-camera**: Multiple simultaneous dispensers
6. **â˜ï¸ Cloud**: AWS/GCP deployment for scalability
7. **ğŸ“± Mobile app**: Smartphone monitoring
8. **ğŸ¤– Auto-retraining**: Continuous model improvement

---

## ğŸ‘¨â€ğŸ’» Development

**Author**: HÃ©ctor Madrigal 
**Project**: Practical Case - Intern Full Stack & AI Developer  
**Tech Stack**: Python, FastAPI, YOLOv8, SQLite, Docker, TailwindCSS  
**License**: Educational/demonstrative use

**Clean structure for delivery** (~5.5 GB removed):
- âŒ Virtual environments (venv, .conda)
- âŒ Old videos (backend/uploads empty)
- âŒ Old training runs (only train_corrected2)
- âœ… Essential code and complete documentation

### Development Structure
```bash
experimental/          # Development/testing scripts
â”œâ”€â”€ realtime_cup_detector.py  # Real-time detector (debug)
â”œâ”€â”€ train_model.py    # Model retraining
â””â”€â”€ ...

tools/                # Auxiliary tools
â”œâ”€â”€ configure_rois.py # Adjust regions of interest
â””â”€â”€ ...
```

### Retrain the Model
```bash
# Prepare dataset
python prepare_dataset.py

# Train
python train_model.py
```

---

## ğŸ“š Additional Documentation

- [docs/PROJECT_STRUCTURE.md](docs/PROJECT_STRUCTURE.md) - Detailed structure
- [docs/TECHNICAL.md](docs/TECHNICAL.md) - Advanced technical details
- API Docs: `http://localhost:8000/docs` (Swagger UI)

---

## ğŸ“„ License

This project was developed as a practical case for selection process.

---

## ğŸ¤ Author

Developed for the **Intern Full Stack & AI Developer** practical case

**Delivery date:** February 2026

---

**ğŸ¯ Production-ready system with applied optimizations and complete documentation.**
